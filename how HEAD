[33mcommit df21255b172bab7e44aaab9546544cfcd48c7a4d[m[33m ([m[1;36mHEAD[m[33m -> [m[1;32mmain[m[33m, [m[1;31morigin/main[m[33m, [m[1;31morigin/HEAD[m[33m)[m
Author: BinhHoaa <BinhTh.B23KD008@stu.ptit.edu.vn>
Date:   Mon Nov 10 18:38:38 2025 +0700

    háº¹ háº¹ háº¹

[1mdiff --git a/.github/copilot-instructions.md b/.github/copilot-instructions.md[m
[1mindex 81cac20..0dbd649 100644[m
[1m--- a/.github/copilot-instructions.md[m
[1m+++ b/.github/copilot-instructions.md[m
[36m@@ -151,4 +151,6 @@[m [mrealestate/[m
 - Monitor MinIO bucket for data persistence</content>[m
 <parameter name="filePath">.github/copilot-instructions.md[m
 [m
[31m-before running any file, activate the virtual environment in `src/pipelines/real-estate/.venv`[m
\ No newline at end of file[m
[32m+[m[32mbefore running any file, activate the virtual environment in `src/pipelines/real-estate/.venv`[m
[32m+[m
[32m+[m[32mall project code is under `src/pipelines/real-estate/`[m
\ No newline at end of file[m
[1mdiff --git a/.gitignore b/.gitignore[m
[1mindex 98a0ee9..d835e82 100644[m
[1m--- a/.gitignore[m
[1m+++ b/.gitignore[m
[36m@@ -185,3 +185,6 @@[m [mtmp_*/[m
 [m
 # Data lake directories (Delta Lake data)[m
 src/pipelines/real-estate/lake/[m
[32m+[m
[32m+[m[32m#[m
[32m+[m[32m.github[m[41m [m
\ No newline at end of file[m
[1mdiff --git a/README.md b/README.md[m
[1mindex 937e654..d66174a 100644[m
[1m--- a/README.md[m
[1m+++ b/README.md[m
[36m@@ -10,31 +10,33 @@[m [mMá»™t pipeline data engineering thá»±c táº¿ Ä‘á»ƒ thu tháº­p, xá»­ lÃ½ vÃ  phÃ¢n[m
 - [CÃ i Ä‘áº·t vÃ  cháº¡y](#-cÃ i-Ä‘áº·t-vÃ -cháº¡y)[m
 - [Sá»­ dá»¥ng pipeline](#-sá»­-dá»¥ng-pipeline)[m
 - [Data Exploration](#-data-exploration)[m
[32m+[m[32m- [PostgreSQL Export](#ï¸-postgresql-export)[m
 - [Cáº¥u trÃºc thÆ° má»¥c](#-cáº¥u-trÃºc-thÆ°-má»¥c)[m
 [m
 ## Kiáº¿n trÃºc dá»± Ã¡n[m
 [m
 ```[m
[31m-â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”[m
[31m-â”‚   Web Scraping  â”‚ -> â”‚   Data Process  â”‚ -> â”‚   Delta Lake    â”‚ -> â”‚   Data Explore  â”‚[m
[31m-â”‚  (Requests + BS)â”‚    â”‚   (Pandas)      â”‚    â”‚   (MinIO S3)    â”‚    â”‚   (Jupyter)     â”‚[m
[31m-â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜[m
[31m-         â”‚                       â”‚                       â”‚                       â”‚[m
[31m-         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜[m
[31m-                                 â”‚                       â”‚[m
[31m-                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”[m
[31m-                    â”‚    Dagster     â”‚         â”‚    Analytics    â”‚[m
[31m-                    â”‚ Orchestration  â”‚         â”‚   (DuckDB)      â”‚[m
[31m-                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜[m
[32m+[m[32mâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”[m
[32m+[m[32mâ”‚   Web Scraping  â”‚ -> â”‚   Data Process  â”‚ -> â”‚   Delta Lake    â”‚ -> â”‚   PostgreSQL    â”‚ -> â”‚   Data Explore  â”‚[m
[32m+[m[32mâ”‚  (Requests + BS)â”‚    â”‚   (Pandas)      â”‚    â”‚   (MinIO S3)    â”‚    â”‚   (Export)      â”‚    â”‚   (Jupyter)     â”‚[m
[32m+[m[32mâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜[m
[32m+[m[32m         â”‚                       â”‚                       â”‚                       â”‚                       â”‚[m
[32m+[m[32m         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜[m
[32m+[m[32m                                 â”‚                       â”‚                       â”‚[m
[32m+[m[32m                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”[m
[32m+[m[32m                    â”‚    Dagster     â”‚         â”‚    Analytics    â”‚    â”‚   SQL Queries   â”‚[m
[32m+[m[32m                    â”‚ Orchestration  â”‚         â”‚   (DuckDB)      â”‚    â”‚  (PostgreSQL)   â”‚[m
[32m+[m[32m                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜[m
 ```[m
 [m
 ### Luá»“ng xá»­ lÃ½ dá»¯ liá»‡u:[m
 1. **Scraping Layer**: Thu tháº­p dá»¯ liá»‡u tá»« nhadat247.com.vn sá»­ dá»¥ng requests + BeautifulSoup, trÃ¡nh DNS issues[m
 2. **Processing Layer**: Xá»­ lÃ½ dá»¯ liá»‡u vá»›i Pandas, chuáº©n hÃ³a format[m
 3. **Storage Layer**: LÆ°u trá»¯ ACID vá»›i Delta Lake trÃªn MinIO S3-compatible[m
[31m-4. **Exploration Layer**: PhÃ¢n tÃ­ch dá»¯ liá»‡u vá»›i Jupyter notebooks vÃ  DuckDB[m
[32m+[m[32m4. **Database Layer**: Tá»± Ä‘á»™ng export tá»« Delta Lake sang PostgreSQL trong pipeline[m
[32m+[m[32m5. **Analytics Layer**: Cháº¡y SQL queries vÃ  Jupyter notebooks cho data exploration[m
 [m
[31m-**Key Data Flow**: Search Criteria â†’ URL Generation â†’ Threaded Requests Scraping â†’ DataFrame Processing â†’ Delta Lake Merge â†’ Jupyter Exploration[m
[32m+[m[32m**Key Data Flow**: Search Criteria â†’ URL Generation â†’ Threaded Requests Scraping â†’ DataFrame Processing â†’ Delta Lake Merge â†’ PostgreSQL Export â†’ SQL Analytics[m
 [m
 ## TÃ­nh nÄƒng chÃ­nh[m
 [m
[36m@@ -42,7 +44,9 @@[m [mMá»™t pipeline data engineering thá»±c táº¿ Ä‘á»ƒ thu tháº­p, xá»­ lÃ½ vÃ  phÃ¢n[m
 - âœ… **ACID Transactions**: Delta Lake Ä‘áº£m báº£o tÃ­nh toÃ n váº¹n dá»¯ liá»‡u[m
 - âœ… **Schema Evolution**: Tá»± Ä‘á»™ng adapt khi schema thay Ä‘á»•i[m
 - âœ… **Cloud Storage**: MinIO S3-compatible cho storage agnostic[m
[31m-- âœ… **Data Exploration**: Jupyter notebooks vá»›i DuckDB analytics[m
[32m+[m[32m- âœ… **PostgreSQL Integration**: Pipeline tá»± Ä‘á»™ng export tá»« Delta Lake sang PostgreSQL[m
[32m+[m[32m- âœ… **Analytics Queries**: Script chuyÃªn dá»¥ng Ä‘á»ƒ cháº¡y SQL analytics trÃªn PostgreSQL[m
[32m+[m[32m- âœ… **Data Exploration**: Jupyter notebooks vá»›i DuckDB vÃ  PostgreSQL queries[m
 - âœ… **Monitoring**: Dagster UI cho pipeline monitoring[m
 [m
 ## ğŸ› ï¸ CÃ´ng nghá»‡ sá»­ dá»¥ng[m
[36m@@ -50,25 +54,24 @@[m [mMá»™t pipeline data engineering thá»±c táº¿ Ä‘á»ƒ thu tháº­p, xá»­ lÃ½ vÃ  phÃ¢n[m
 ### Core Dependencies[m
 - **Dagster 1.6.8**: Workflow orchestration vÃ  pipeline management[m
 - **Dagster-DeltaLake-Pandas**: Delta Lake integration vá»›i Pandas[m
[32m+[m[32m- **Dagster-Postgres**: PostgreSQL integration[m
 - **Delta Lake**: ACID transactions vÃ  time travel cho data lake[m
[32m+[m[32m- **PostgreSQL**: Relational database cho analytics vÃ  reporting[m
 - **MinIO**: S3-compatible object storage[m
 - **PyArrow**: Apache Arrow cho data processing[m
 - **Pandas**: Data manipulation vÃ  analysis[m
 - **DuckDB**: In-process analytical database (sá»­ dá»¥ng trong notebooks)[m
[32m+[m[32m- **SQLAlchemy**: ORM cho database operations[m
 - **Requests**: HTTP client cho web scraping[m
 - **BeautifulSoup4**: HTML parsing[m
 - **Boto3**: AWS S3 API client (MinIO compatible)[m
 [m
 ### Development & Deployment[m
 - **Dagstermill**: Jupyter notebook integration vá»›i Dagster[m
[32m+[m[32m- **PostgreSQL Export Op**: TÃ­ch há»£p export vÃ o pipeline Dagster[m
 [m
 ## CÃ i Ä‘áº·t vÃ  cháº¡y[m
 [m
[31m-### Prerequisites[m
[31m-- Python 3.8+[m
[31m-- Git[m
[31m-- Windows OS[m
[31m-[m
 ### 1. Clone repository[m
 ```bash[m
 git clone https://github.com/BinhTHB/Real-Estate_Project.git[m
[36m@@ -92,6 +95,7 @@[m [mpip install -r dev-requirements.txt[m
 Dependencies chÃ­nh bao gá»“m:[m
 - Dagster ecosystem (dagster, dagstermill, dagster-aws, dagster-postgres, dagster-deltalake)[m
 - Data processing (pandas, pyarrow, numpy, scipy, scikit-learn)[m
[32m+[m[32m- Database (sqlalchemy, psycopg2-binary)[m
 - Web scraping (requests, beautifulsoup4)[m
 - Cloud storage (boto3)[m
 - Analytics (duckdb, seaborn, matplotlib, folium)[m
[36m@@ -107,47 +111,150 @@[m [mMinIO sáº½ cháº¡y táº¡i:[m
 - **Username**: `minioadmin`[m
 - **Password**: `minioadmin`[m
 [m
[31m-### 4. Startup dagster[m
[32m+[m[32m### 4. Cháº¡y pipeline Ä‘áº§y Ä‘á»§[m
[32m+[m
 ```bash[m
[32m+[m[32m# Khá»Ÿi Ä‘á»™ng Dagster UI[m
 dagster dev[m
[32m+[m
[32m+[m[32m# Má»Ÿ http://127.0.0.1:3000 vÃ  cháº¡y job scrape_realestate[m
[32m+[m[32m# Pipeline sáº½ tá»± Ä‘á»™ng: Scrape â†’ Delta Lake â†’ PostgreSQL Export â†’ Analytics[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### 5. Cháº¡y analytics queries (tÃ¹y chá»n)[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32mcd src/pipelines/real-estate[m
[32m+[m
[32m+[m[32m# Cháº¡y analytics queries trÃªn dá»¯ liá»‡u PostgreSQL[m
[32m+[m[32mpython postgres_analytics.py[m
 ```[m
 [m
 ## Sá»­ dá»¥ng pipeline[m
 [m
[31m-### Cháº¡y pipeline scraping[m
[32m+[m[32m### Cháº¡y pipeline Ä‘áº§y Ä‘á»§[m
 [m
[31m-1. Má»Ÿ Dagster UI táº¡i http://127.0.0.1:3000[m
[31m-2. Chá»n job `scrape_realestate`[m
[31m-3. Launch vá»›i configuration máº·c Ä‘á»‹nh hoáº·c tÃ¹y chá»‰nh:[m
[32m+[m[32m1. Khá»Ÿi Ä‘á»™ng MinIO vÃ  Dagster:[m
[32m+[m[32m```bash[m
[32m+[m[32m# Terminal 1: MinIO[m
[32m+[m[32mminio server /tmp/minio/[m
 [m
[31m-```yaml[m
[31m-# scrape_realestate.yaml[m
[31m-solids:[m
[31m-  collect_search_criterias:[m
[31m-    inputs:[m
[31m-      search_criterias:[m
[31m-        - city: "hanoi"[m
[31m-          propertyType: "can-ho-chung-cu"[m
[31m-          rentOrBuy: "buy"[m
[31m-          radius: 0[m
[32m+[m[32m# Terminal 2: Dagster[m
[32m+[m[32mdagster dev[m
 ```[m
 [m
[31m-### Monitoring pipeline[m
[32m+[m[32m2. Má»Ÿ Dagster UI táº¡i http://127.0.0.1:3000[m
[32m+[m[32m3. Chá»n job `scrape_realestate` vÃ  launch[m
 [m
[31m-Dagster UI cung cáº¥p:[m
[31m-- âœ… **Pipeline runs**: Lá»‹ch sá»­ executions[m
[31m-- âœ… **Logs**: Chi tiáº¿t tá»«ng step[m
[31m-- âœ… **Data lineage**: Flow cá»§a data[m
[31m-- âœ… **Asset catalog**: Datasets Ä‘Æ°á»£c táº¡o[m
[32m+[m[32m**Pipeline sáº½ tá»± Ä‘á»™ng thá»±c hiá»‡n:**[m
[32m+[m[32m- âœ… Scrape dá»¯ liá»‡u tá»« nhadat247.com.vn[m
[32m+[m[32m- âœ… LÆ°u vÃ o Delta Lake trÃªn MinIO[m
[32m+[m[32m- âœ… Export dá»¯ liá»‡u sang PostgreSQL[m
[32m+[m[32m- âœ… Cháº¡y data exploration notebook[m
 [m
 ## ğŸ” Data Exploration[m
 [m
[31m-### Jupyter Notebook[m
[32m+[m[32m### PostgreSQL Analytics[m
[32m+[m
[32m+[m[32mSau khi export dá»¯ liá»‡u sang PostgreSQL, cÃ³ thá»ƒ sá»­ dá»¥ng SQL queries trá»±c tiáº¿p cho analytics:[m
[32m+[m
[32m+[m[32m```sql[m
[32m+[m[32m-- Thá»‘ng kÃª cÆ¡ báº£n[m
[32m+[m[32mSELECT[m[41m [m
[32m+[m[32m    COUNT(*) as total_properties,[m
[32m+[m[32m    AVG(muc_gia::float) as avg_price,[m
[32m+[m[32m    MIN(muc_gia::float) as min_price,[m
[32m+[m[32m    MAX(muc_gia::float) as max_price,[m
[32m+[m[32m    AVG(dien_tich::float) as avg_area[m
[32m+[m[32mFROM real_estate_properties[m
[32m+[m[32mWHERE muc_gia IS NOT NULL AND dien_tich IS NOT NULL;[m
[32m+[m
[32m+[m[32m-- GiÃ¡ theo khu vá»±c[m
[32m+[m[32mSELECT[m[41m [m
[32m+[m[32m    ia_chi,[m
[32m+[m[32m    COUNT(*) as property_count,[m
[32m+[m[32m    AVG(muc_gia::float) as avg_price[m
[32m+[m[32mFROM real_estate_properties[m
[32m+[m[32mWHERE ia_chi IS NOT NULL[m
[32m+[m[32mGROUP BY ia_chi[m
[32m+[m[32mORDER BY avg_price DESC;[m
[32m+[m
[32m+[m[32m-- PhÃ¢n tÃ­ch theo loáº¡i báº¥t Ä‘á»™ng sáº£n[m
[32m+[m[32mSELECT[m[41m [m
[32m+[m[32m    property_type,[m
[32m+[m[32m    COUNT(*) as count,[m
[32m+[m[32m    AVG(muc_gia::float) as avg_price,[m
[32m+[m[32m    AVG(dien_tich::float) as avg_area[m
[32m+[m[32mFROM real_estate_properties[m
[32m+[m[32mWHERE property_type IS NOT NULL[m
[32m+[m[32mGROUP BY property_type[m
[32m+[m[32mORDER BY count DESC;[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Python Analytics vá»›i PostgreSQL[m
 [m
[31m-Pipeline tá»± Ä‘á»™ng cháº¡y notebook `main_notebook.ipynb` sau khi scrape data. Notebook sá»­ dá»¥ng DuckDB Ä‘á»ƒ query data tá»« Delta Lake trÃªn MinIO:[m
[32m+[m[32mSá»­ dá»¥ng SQLAlchemy hoáº·c pandas Ä‘á»ƒ káº¿t ná»‘i vÃ  phÃ¢n tÃ­ch:[m
[32m+[m
[32m+[m[32m```python[m
[32m+[m[32mimport pandas as pd[m
[32m+[m[32mimport sqlalchemy as sa[m
[32m+[m[32mimport matplotlib.pyplot as plt[m
[32m+[m[32mimport seaborn as sns[m
[32m+[m
[32m+[m[32m# Káº¿t ná»‘i PostgreSQL[m
[32m+[m[32mengine = sa.create_engine('postgresql://user:password@host:port/database')[m
[32m+[m
[32m+[m[32m# Query dá»¯ liá»‡u[m
[32m+[m[32mquery = """[m
[32m+[m[32mSELECT[m[41m [m
[32m+[m[32m    muc_gia::float as price,[m
[32m+[m[32m    dien_tich::float as area,[m
[32m+[m[32m    ia_chi as location,[m
[32m+[m[32m    latitude,[m
[32m+[m[32m    longitude[m
[32m+[m[32mFROM real_estate_properties[m
[32m+[m[32mWHERE muc_gia IS NOT NULL[m[41m [m
[32m+[m[32m  AND dien_tich IS NOT NULL[m[41m [m
[32m+[m[32m  AND latitude IS NOT NULL[m
[32m+[m[32m"""[m
[32m+[m
[32m+[m[32mdf = pd.read_sql(query, engine)[m
[32m+[m
[32m+[m[32m# Visualization[m
[32m+[m[32mplt.figure(figsize=(12, 8))[m
[32m+[m[32msns.scatterplot(data=df, x='area', y='price', alpha=0.6)[m
[32m+[m[32mplt.title('GiÃ¡ báº¥t Ä‘á»™ng sáº£n theo diá»‡n tÃ­ch')[m
[32m+[m[32mplt.xlabel('Diá»‡n tÃ­ch (mÂ²)')[m
[32m+[m[32mplt.ylabel('GiÃ¡ (tá»· VNÄ)')[m
[32m+[m[32mplt.show()[m
[32m+[m
[32m+[m[32m# Thá»‘ng kÃª theo khu vá»±c[m
[32m+[m[32mlocation_stats = df.groupby('location').agg({[m
[32m+[m[32m    'price': ['count', 'mean', 'median'],[m
[32m+[m[32m    'area': 'mean'[m
[32m+[m[32m}).round(2)[m
[32m+[m
[32m+[m[32mprint(location_stats.head(10))[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32mSau khi pipeline hoÃ n thÃ nh, sá»­ dá»¥ng script `postgres_analytics.py` Ä‘á»ƒ cháº¡y analytics queries trÃªn dá»¯ liá»‡u PostgreSQL:[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32mcd src/pipelines/real-estate[m
[32m+[m
[32m+[m[32m# Cháº¡y analytics queries trÃªn dá»¯ liá»‡u PostgreSQL[m
[32m+[m[32mpython postgres_analytics.py[m
[32m+[m
[32m+[m[32m# Vá»›i tÃ¹y chá»n giá»›i háº¡n káº¿t quáº£[m
[32m+[m[32mpython postgres_analytics.py --limit-results 20[m
[32m+[m[32m```[m
[32m+[m
[32m+[m
[32m+[m[32m### Jupyter Notebook (TÃ¹y chá»n)[m
[32m+[m
[32m+[m[32mPipeline cÅ©ng há»— trá»£ Jupyter notebook vá»›i DuckDB Ä‘á»ƒ query data tá»« Delta Lake trÃªn MinIO:[m
 [m
 ```python[m
[31m-# Trong notebook cÃ³ thá»ƒ:[m
 import duckdb[m
 import pandas as pd[m
 [m
[36m@@ -162,66 +269,50 @@[m [mSET s3_secret_access_key='minioadmin';[m
 [m
 # Query data tá»« Delta Lake[m
 df = duckdb.sql("SELECT * FROM read_parquet(['s3://real-estate/lake/bronze/property/*.parquet'])").df()[m
[31m-[m
[31m-# Analytics vá»›i DuckDB[m
[31m-result = duckdb.sql("""[m
[31m-    SELECT[m
[31m-        "Má»©c giÃ¡",[m
[31m-        "Diá»‡n tÃ­ch", [m
[31m-        latitude,[m
[31m-        longitude,[m
[31m-        COUNT(*) as count[m
[31m-    FROM df[m
[31m-    GROUP BY "Má»©c giÃ¡", "Diá»‡n tÃ­ch", latitude, longitude[m
[31m-""").df()[m
 ```[m
 [m
 ### Data Schema[m
 [m
 Dá»¯ liá»‡u thu tháº­p bao gá»“m:[m
 - `url`: Link bÃ i Ä‘Äƒng[m
[31m-- `TiÃªu Ä‘á»`: TiÃªu Ä‘á» báº¥t Ä‘á»™ng sáº£n  [m
[31m-- `Má»©c giÃ¡`: GiÃ¡ (tá»·/triá»‡u VNÄ)[m
[31m-- `Diá»‡n tÃ­ch`: Diá»‡n tÃ­ch (mÂ²)[m
[31m-- `Äá»‹a chá»‰`: Äá»‹a chá»‰ chi tiáº¿t[m
[32m+[m[32m- `tieu_e`: TiÃªu Ä‘á» báº¥t Ä‘á»™ng sáº£n[m[41m  [m
[32m+[m[32m- `muc_gia`: GiÃ¡ (tá»·/triá»‡u VNÄ)[m
[32m+[m[32m- `dien_tich`: Diá»‡n tÃ­ch (mÂ²)[m
[32m+[m[32m- `ia_chi`: Äá»‹a chá»‰ chi tiáº¿t[m
 - `latitude/longitude`: Tá»a Ä‘á»™ GPS[m
[31m-- `propertyDetails_propertyId`: ID unique (hash tá»« URL)[m
[31m-- `NgÃ y Ä‘Äƒng`: NgÃ y thu tháº­p dá»¯ liá»‡u[m
[32m+[m[32m- `propertydetails_propertyid`: ID unique (hash tá»« URL)[m
[32m+[m[32m- `ngay_ang`: NgÃ y thu tháº­p dá»¯ liá»‡u[m
 [m
[31m-## Cáº¥u trÃºc thÆ° má»¥c[m
[32m+[m[32m### Export tÃ­ch há»£p trong Pipeline[m
 [m
[31m-```[m
[31m-Real-Estate_Project/[m
[31m-â”œâ”€â”€ src/[m
[31m-â”‚   â””â”€â”€ pipelines/[m
[31m-â”‚       â””â”€â”€ real-estate/[m
[31m-â”‚           â”œâ”€â”€ realestate/           # Core pipeline code[m
[31m-â”‚           â”‚   â”œâ”€â”€ pipelines.py      # Main job definitions vÃ  orchestration[m
[31m-â”‚           â”‚   â”œâ”€â”€ resources.py      # Dagster resources (database/S3 configs)[m
[31m-â”‚           â”‚   â”œâ”€â”€ common/           # Shared utilities[m
[31m-â”‚           â”‚   â”‚   â”œâ”€â”€ requests_scraping.py    # Web scraping logic (requests + BS4)[m
[31m-â”‚           â”‚   â”‚   â”œâ”€â”€ solids_spark_delta.py   # Delta Lake operations (merge/upsert)[m
[31m-â”‚           â”‚   â”‚   â”œâ”€â”€ types_realestate.py     # Custom data types[m
[31m-â”‚           â”‚   â”‚   â”œâ”€â”€ helper_functions.py     # Utility functions[m
[31m-â”‚           â”‚   â”‚   â”œâ”€â”€ solids_jupyter.py       # Notebook integration[m
[31m-â”‚           â”‚   â”‚   â””â”€â”€ resources.py            # Resource definitions (boto3, etc.)[m
[31m-â”‚           â”‚   â”œâ”€â”€ config_environments/        # Environment configs (local/prod)[m
[31m-â”‚           â”‚   â”œâ”€â”€ config_pipelines/          # Pipeline execution parameters[m
[31m-â”‚           â”‚   â””â”€â”€ notebooks/                 # Data exploration notebooks[m
[31m-â”‚           â”œâ”€â”€ setup.py                       # Package setup vá»›i dependencies[m
[31m-â”‚           â”œâ”€â”€ pyproject.toml                 # Project metadata[m
[31m-â”‚           â”œâ”€â”€ dev-requirements.txt           # Development dependencies[m
[31m-â”‚           â””â”€â”€ tox.ini                        # Testing configuration[m
[31m-â”œâ”€â”€ lake/bronze/                  # Delta Lake storage (runtime)[m
[31m-â”œâ”€â”€ PRODUCTION_FEATURES_GUIDE.md   # Production deployment guide[m
[31m-â”œâ”€â”€ .github/copilot-instructions.md # AI assistant instructions[m
[31m-â””â”€â”€ README.md                      # This file[m
[32m+[m[32mExport dá»¯ liá»‡u tá»« Delta Lake sang PostgreSQL Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p trá»±c tiáº¿p vÃ o pipeline Dagster. Khi cháº¡y job `scrape_realestate`, pipeline sáº½ tá»± Ä‘á»™ng:[m
[32m+[m
[32m+[m[32m1. âœ… **Scrape dá»¯ liá»‡u** tá»« nhadat247.com.vn[m
[32m+[m[32m2. âœ… **LÆ°u vÃ o Delta Lake** trÃªn MinIO S3-compatible[m
[32m+[m[32m3. âœ… **Export sang PostgreSQL** vá»›i schema auto-detection[m
[32m+[m[32m4. âœ… **Táº¡o indexes** cho performance[m
[32m+[m[32m5. âœ… **Verify dá»¯ liá»‡u** sau export[m
[32m+[m
[32m+[m
[32m+[m[32m### Cáº¥u hÃ¬nh PostgreSQL[m
[32m+[m
[32m+[m[32mFile `postgres_credentials.yaml` chá»©a thÃ´ng tin káº¿t ná»‘i:[m
[32m+[m
[32m+[m[3