# ğŸ  Real Estate Project

[![Dagster](https://img.shields.io/badge/Dagster-1.6.8-blue)](https://dagster.io/)
[![Delta Lake](https://img.shields.io/badge/Delta_Lake-3.0.0-green)](https://delta.io/)
[![MinIO](https://img.shields.io/badge/MinIO-S3-orange)](https://min.io/)
[![Python](https://img.shields.io/badge/Python-3.8+-yellow)](https://python.org/)

Má»™t pipeline data engineering thá»±c táº¿ Ä‘á»ƒ thu tháº­p, xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u báº¥t Ä‘á»™ng sáº£n Viá»‡t Nam tá»« nhadat247.com.vn.

## ğŸ“‹ Má»¥c lá»¥c

- [ğŸ—ï¸ Kiáº¿n trÃºc dá»± Ã¡n](#-kiáº¿n-trÃºc-dá»±-Ã¡n)
- [âœ¨ TÃ­nh nÄƒng chÃ­nh](#-tÃ­nh-nÄƒng-chÃ­nh)
- [ğŸ› ï¸ CÃ´ng nghá»‡ sá»­ dá»¥ng](#ï¸-cÃ´ng-nghá»‡-sá»­-dá»¥ng)
- [ğŸš€ CÃ i Ä‘áº·t vÃ  cháº¡y](#-cÃ i-Ä‘áº·t-vÃ -cháº¡y)
- [ğŸ“Š Sá»­ dá»¥ng pipeline](#-sá»­-dá»¥ng-pipeline)
- [ğŸ” Data Exploration](#-data-exploration)
- [ğŸ“ Cáº¥u trÃºc thÆ° má»¥c](#-cáº¥u-trÃºc-thÆ°-má»¥c)
- [ğŸ¤ ÄÃ³ng gÃ³p](#-Ä‘Ã³ng-gÃ³p)

## ğŸ—ï¸ Kiáº¿n trÃºc dá»± Ã¡n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Scraping  â”‚ -> â”‚   Data Process  â”‚ -> â”‚   Delta Lake    â”‚ -> â”‚   Data Explore  â”‚
â”‚  (Requests + BS)â”‚    â”‚   (Pandas)      â”‚    â”‚   (MinIO S3)    â”‚    â”‚   (Jupyter)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Dagster     â”‚         â”‚    DuckDB       â”‚
                    â”‚ Orchestration  â”‚         â”‚   Analytics     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Luá»“ng xá»­ lÃ½ dá»¯ liá»‡u:
1. **Scraping Layer**: Thu tháº­p dá»¯ liá»‡u tá»« nhadat247.com.vn sá»­ dá»¥ng requests + BeautifulSoup
2. **Processing Layer**: Xá»­ lÃ½ dá»¯ liá»‡u vá»›i Pandas, chuáº©n hÃ³a format
3. **Storage Layer**: LÆ°u trá»¯ ACID vá»›i Delta Lake trÃªn MinIO S3-compatible
4. **Exploration Layer**: PhÃ¢n tÃ­ch dá»¯ liá»‡u vá»›i Jupyter notebooks vÃ  DuckDB

## âœ¨ TÃ­nh nÄƒng chÃ­nh

- âœ… **Web Scraping á»•n Ä‘á»‹nh**: Sá»­ dá»¥ng requests thay vÃ¬ Selenium, trÃ¡nh DNS issues
- âœ… **ACID Transactions**: Delta Lake Ä‘áº£m báº£o tÃ­nh toÃ n váº¹n dá»¯ liá»‡u
- âœ… **Schema Evolution**: Tá»± Ä‘á»™ng adapt khi schema thay Ä‘á»•i
- âœ… **Cloud Storage**: MinIO S3-compatible cho storage agnostic
- âœ… **Data Exploration**: Jupyter notebooks vá»›i DuckDB analytics
- âœ… **Monitoring**: Dagster UI cho pipeline monitoring

## ğŸ› ï¸ CÃ´ng nghá»‡ sá»­ dá»¥ng

### Core Dependencies
- **Dagster 1.6.8**: Workflow orchestration vÃ  pipeline management
- **Delta Lake**: ACID transactions vÃ  time travel cho data lake
- **MinIO**: S3-compatible object storage
- **PyArrow**: Apache Arrow cho data processing
- **Pandas**: Data manipulation vÃ  analysis
- **DuckDB**: In-process analytical database

### Scraping & Processing
- **Requests**: HTTP client cho web scraping
- **BeautifulSoup4**: HTML parsing
- **Boto3**: AWS S3 API client (MinIO compatible)

### Development & Deployment
- **Dagstermill**: Jupyter notebook integration vá»›i Dagster

## ğŸš€ CÃ i Ä‘áº·t vÃ  cháº¡y

### Prerequisites
- Python 3.8+
- Git
- Windows OS

### 1. Clone repository
```bash
git clone https://github.com/BinhTHB/Real-Estate_Project_Data_Engineering.git
cd Real-Estate_Project_Data_Engineering
```

### 2. CÃ i Ä‘áº·t dependencies
```bash
cd src/pipelines/real-estate
pip install -e ".[dev]"
```

### 3. Khá»Ÿi Ä‘á»™ng MinIO storage
```bash
# Windows
.\MinIO_run.bat
```

MinIO sáº½ cháº¡y táº¡i:
- **API Endpoint**: `http://127.0.0.1:9000`
- **Web Console**: `http://127.0.0.1:9001`
- **Username**: `minioadmin`
- **Password**: `minioadmin`

### 4. Quick deployment (Alternative)
```bash
# Run everything with one command
.\deploy_production.bat
```

Script nÃ y sáº½ tá»± Ä‘á»™ng:
- Khá»Ÿi Ä‘á»™ng MinIO storage
- Chá» MinIO sáºµn sÃ ng
- Khá»Ÿi Ä‘á»™ng Dagster development server
- Hiá»ƒn thá»‹ táº¥t cáº£ access points
```bash
dagster dev --port 3000
```

Truy cáº­p Dagster UI táº¡i: http://localhost:3000

## ğŸ“Š Sá»­ dá»¥ng pipeline

### Cháº¡y pipeline scraping

1. Má»Ÿ Dagster UI táº¡i http://localhost:3000
2. Chá»n job `scrape_realestate`
3. Launch vá»›i configuration máº·c Ä‘á»‹nh hoáº·c tÃ¹y chá»‰nh:

```yaml
# scrape_realestate.yaml
solids:
  collect_search_criterias:
    inputs:
      search_criterias:
        - city: "hanoi"
          propertyType: "can-ho-chung-cu"
          rentOrBuy: "buy"
          radius: 0
```

### Monitoring pipeline

Dagster UI cung cáº¥p:
- âœ… **Pipeline runs**: Lá»‹ch sá»­ executions
- âœ… **Logs**: Chi tiáº¿t tá»«ng step
- âœ… **Data lineage**: Flow cá»§a data
- âœ… **Asset catalog**: Datasets Ä‘Æ°á»£c táº¡o

## ğŸ” Data Exploration

### Jupyter Notebook

Pipeline tá»± Ä‘á»™ng cháº¡y notebook `TEST.ipynb` sau khi scrape data:

```python
# Trong notebook cÃ³ thá»ƒ:
import duckdb
import pandas as pd

# Query data tá»« Delta Lake
df = duckdb.sql("SELECT * FROM read_parquet(['s3://real-estate/lake/bronze/property/*.parquet'])").df()

# Analytics vá»›i DuckDB
result = duckdb.sql("""
    SELECT
        "Má»©c giÃ¡",
        "Diá»‡n tÃ­ch",
        latitude,
        longitude,
        COUNT(*) as count
    FROM df
    GROUP BY "Má»©c giÃ¡", "Diá»‡n tÃ­ch", latitude, longitude
""").df()
```

### Data Schema

Dá»¯ liá»‡u thu tháº­p bao gá»“m:
- `url`: Link bÃ i Ä‘Äƒng
- `TiÃªu Ä‘á»`: TiÃªu Ä‘á» báº¥t Ä‘á»™ng sáº£n
- `Má»©c giÃ¡`: GiÃ¡ (tá»·/triá»‡u VNÄ)
- `Diá»‡n tÃ­ch`: Diá»‡n tÃ­ch (mÂ²)
- `Äá»‹a chá»‰`: Äá»‹a chá»‰ chi tiáº¿t
- `latitude/longitude`: Tá»a Ä‘á»™ GPS
- `propertyDetails_propertyId`: ID unique (hash tá»« URL)

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
Real-Estate_Project_Data_Engineering/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ pipelines/
â”‚       â””â”€â”€ real-estate/
â”‚           â”œâ”€â”€ realestate/           # Core pipeline code
â”‚           â”‚   â”œâ”€â”€ common/           # Shared utilities
â”‚           â”‚   â”‚   â”œâ”€â”€ requests_scraping.py    # Web scraping logic
â”‚           â”‚   â”‚   â”œâ”€â”€ solids_spark_delta.py   # Delta Lake operations
â”‚           â”‚   â”‚   â”œâ”€â”€ solids_jupyter.py       # Notebook integration
â”‚           â”‚   â”‚   â””â”€â”€ types_realestate.py     # Custom types
â”‚           â”‚   â”œâ”€â”€ config_environments/        # Environment configs
â”‚           â”‚   â”œâ”€â”€ config_pipelines/          # Pipeline configs
â”‚           â”‚   â”œâ”€â”€ notebooks/                 # Data exploration
â”‚           â”‚   â”œâ”€â”€ pipelines.py               # Main pipeline definition
â”‚           â”‚   â””â”€â”€ resources.py               # Dagster resources
â”‚           â”œâ”€â”€ setup.py                       # Package setup
â”‚           â””â”€â”€ pyproject.toml                 # Project metadata
â”œâ”€â”€ MinIO_run.bat                  # MinIO startup script
â”œâ”€â”€ deploy_production.bat          # Production deployment script
â”œâ”€â”€ PRODUCTION_FEATURES_GUIDE.md   # Production features documentation
â”œâ”€â”€ .github/copilot-instructions.md # AI assistant instructions
â””â”€â”€ README.md                      # This file
```

## ğŸ¤ ÄÃ³ng gÃ³p

### Development setup

```bash
# Install development dependencies
pip install -e ".[dev]"

# Run tests
pytest

# Format code
black .
isort .
```

### Code quality

- **Black**: Code formatting
- **isort**: Import sorting
- **pytest**: Unit testing
- **Dagster**: Pipeline testing

### Adding new features

1. Táº¡o feature branch tá»« `main`
2. Implement changes
3. Add tests
4. Update documentation
5. Create pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Dagster](https://dagster.io/) - Workflow orchestration
- [Delta Lake](https://delta.io/) - Data lakehouse
- [MinIO](https://min.io/) - Object storage
- [nhadat247.com.vn](https://nhadat247.com.vn) - Data source

---

**Built with â¤ï¸ for the Vietnamese real estate data engineering community**