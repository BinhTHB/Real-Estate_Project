# Real Estate Project

Má»™t pipeline data engineering thá»±c táº¿ Ä‘á»ƒ thu tháº­p, xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u báº¥t Ä‘á»™ng sáº£n Viá»‡t Nam tá»« nhadat247.com.vn.

## Má»¥c lá»¥c

- [Kiáº¿n trÃºc dá»± Ã¡n](#-kiáº¿n-trÃºc-dá»±-Ã¡n)
- [TÃ­nh nÄƒng chÃ­nh](#-tÃ­nh-nÄƒng-chÃ­nh)
- [CÃ´ng nghá»‡ sá»­ dá»¥ng](#ï¸-cÃ´ng-nghá»‡-sá»­-dá»¥ng)
- [CÃ i Ä‘áº·t vÃ  cháº¡y](#-cÃ i-Ä‘áº·t-vÃ -cháº¡y)
- [Sá»­ dá»¥ng pipeline](#-sá»­-dá»¥ng-pipeline)
- [Data Exploration](#-data-exploration)
- [PostgreSQL Export](#ï¸-postgresql-export)
- [Cáº¥u trÃºc thÆ° má»¥c](#-cáº¥u-trÃºc-thÆ°-má»¥c)

## Kiáº¿n trÃºc dá»± Ã¡n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Scraping  â”‚ -> â”‚   Data Process  â”‚ -> â”‚   Delta Lake    â”‚ -> â”‚   PostgreSQL    â”‚ -> â”‚   Data Explore  â”‚
â”‚  (Requests + BS)â”‚    â”‚   (Pandas)      â”‚    â”‚   (MinIO S3)    â”‚    â”‚   (Export)      â”‚    â”‚   (Jupyter)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚                       â”‚                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Dagster     â”‚         â”‚    Analytics    â”‚    â”‚   SQL Queries   â”‚
                    â”‚ Orchestration  â”‚         â”‚   (DuckDB)      â”‚    â”‚  (PostgreSQL)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Luá»“ng xá»­ lÃ½ dá»¯ liá»‡u:
1. **Scraping Layer**: Thu tháº­p dá»¯ liá»‡u tá»« nhadat247.com.vn sá»­ dá»¥ng requests + BeautifulSoup, trÃ¡nh DNS issues
2. **Processing Layer**: Xá»­ lÃ½ dá»¯ liá»‡u vá»›i Pandas, chuáº©n hÃ³a format
3. **Storage Layer**: LÆ°u trá»¯ ACID vá»›i Delta Lake trÃªn MinIO S3-compatible
4. **Database Layer**: Tá»± Ä‘á»™ng export tá»« Delta Lake sang PostgreSQL trong pipeline
5. **Analytics Layer**: Cháº¡y SQL queries vÃ  Jupyter notebooks cho data exploration

**Key Data Flow**: Search Criteria â†’ URL Generation â†’ Threaded Requests Scraping â†’ DataFrame Processing â†’ Delta Lake Merge â†’ PostgreSQL Export â†’ SQL Analytics

## TÃ­nh nÄƒng chÃ­nh

- âœ… **Web Scraping á»•n Ä‘á»‹nh**: Sá»­ dá»¥ng requests + BeautifulSoup, trÃ¡nh DNS issues cá»§a Chrome/Selenium
- âœ… **ACID Transactions**: Delta Lake Ä‘áº£m báº£o tÃ­nh toÃ n váº¹n dá»¯ liá»‡u
- âœ… **Schema Evolution**: Tá»± Ä‘á»™ng adapt khi schema thay Ä‘á»•i
- âœ… **Cloud Storage**: MinIO S3-compatible cho storage agnostic
- âœ… **PostgreSQL Integration**: Pipeline tá»± Ä‘á»™ng export tá»« Delta Lake sang PostgreSQL
- âœ… **Analytics Queries**: Script chuyÃªn dá»¥ng Ä‘á»ƒ cháº¡y SQL analytics trÃªn PostgreSQL
- âœ… **Data Exploration**: Jupyter notebooks vá»›i DuckDB vÃ  PostgreSQL queries
- âœ… **Monitoring**: Dagster UI cho pipeline monitoring

## ğŸ› ï¸ CÃ´ng nghá»‡ sá»­ dá»¥ng

### Core Dependencies
- **Dagster 1.6.8**: Workflow orchestration vÃ  pipeline management
- **Dagster-DeltaLake-Pandas**: Delta Lake integration vá»›i Pandas
- **Dagster-Postgres**: PostgreSQL integration
- **Delta Lake**: ACID transactions vÃ  time travel cho data lake
- **PostgreSQL**: Relational database cho analytics vÃ  reporting
- **MinIO**: S3-compatible object storage
- **PyArrow**: Apache Arrow cho data processing
- **Pandas**: Data manipulation vÃ  analysis
- **DuckDB**: In-process analytical database (sá»­ dá»¥ng trong notebooks)
- **SQLAlchemy**: ORM cho database operations
- **Requests**: HTTP client cho web scraping
- **BeautifulSoup4**: HTML parsing
- **Boto3**: AWS S3 API client (MinIO compatible)

### Development & Deployment
- **Dagstermill**: Jupyter notebook integration vá»›i Dagster
- **PostgreSQL Export Op**: TÃ­ch há»£p export vÃ o pipeline Dagster

## CÃ i Ä‘áº·t vÃ  cháº¡y

### 1. Clone repository
```bash
git clone https://github.com/BinhTHB/Real-Estate_Project.git
cd Real-Estate_Project
```

### 2. CÃ i Ä‘áº·t dependencies
```bash
cd src/pipelines/real-estate

# Táº¡o virtual environment (náº¿u chÆ°a cÃ³)
python -m venv .venv
# KÃ­ch hoáº¡t virtual environment 
.\venv\Scripts\activate  

pip install -e ".[dev]"

pip install -r dev-requirements.txt
```

Dependencies chÃ­nh bao gá»“m:
- Dagster ecosystem (dagster, dagstermill, dagster-aws, dagster-postgres, dagster-deltalake)
- Data processing (pandas, pyarrow, numpy, scipy, scikit-learn)
- Database (sqlalchemy, psycopg2-binary)
- Web scraping (requests, beautifulsoup4)
- Cloud storage (boto3)
- Analytics (duckdb, seaborn, matplotlib, folium)
- Development (pytest, notebook)

### 3. Khá»Ÿi Ä‘á»™ng MinIO storage
```bash
minio server /tmp/minio/
```

MinIO sáº½ cháº¡y táº¡i:
- **API Endpoint**: `http://127.0.0.1:9000`
- **Username**: `minioadmin`
- **Password**: `minioadmin`

### 4. Cháº¡y pipeline Ä‘áº§y Ä‘á»§

```bash
# Khá»Ÿi Ä‘á»™ng Dagster UI
dagster dev

# Má»Ÿ http://127.0.0.1:3000 vÃ  cháº¡y job scrape_realestate
# Pipeline sáº½ tá»± Ä‘á»™ng: Scrape â†’ Delta Lake â†’ PostgreSQL Export â†’ Analytics
```

### 5. Cháº¡y analytics queries (tÃ¹y chá»n)

```bash
cd src/pipelines/real-estate

# Cháº¡y analytics queries trÃªn dá»¯ liá»‡u PostgreSQL
python postgres_analytics.py
```

## Sá»­ dá»¥ng pipeline

### Cháº¡y pipeline Ä‘áº§y Ä‘á»§

1. Khá»Ÿi Ä‘á»™ng MinIO vÃ  Dagster:
```bash
# Terminal 1: MinIO
minio server /tmp/minio/

# Terminal 2: Dagster
dagster dev
```

2. Má»Ÿ Dagster UI táº¡i http://127.0.0.1:3000
3. Chá»n job `scrape_realestate` vÃ  launch

**Pipeline sáº½ tá»± Ä‘á»™ng thá»±c hiá»‡n:**
- âœ… Scrape dá»¯ liá»‡u tá»« nhadat247.com.vn
- âœ… LÆ°u vÃ o Delta Lake trÃªn MinIO
- âœ… Export dá»¯ liá»‡u sang PostgreSQL
- âœ… Cháº¡y data exploration notebook

## ğŸ” Data Exploration

### PostgreSQL Analytics

Sau khi export dá»¯ liá»‡u sang PostgreSQL, cÃ³ thá»ƒ sá»­ dá»¥ng SQL queries trá»±c tiáº¿p cho analytics:

```sql
-- Thá»‘ng kÃª cÆ¡ báº£n
SELECT 
    COUNT(*) as total_properties,
    AVG(muc_gia::float) as avg_price,
    MIN(muc_gia::float) as min_price,
    MAX(muc_gia::float) as max_price,
    AVG(dien_tich::float) as avg_area
FROM real_estate_properties
WHERE muc_gia IS NOT NULL AND dien_tich IS NOT NULL;

-- GiÃ¡ theo khu vá»±c
SELECT 
    ia_chi,
    COUNT(*) as property_count,
    AVG(muc_gia::float) as avg_price
FROM real_estate_properties
WHERE ia_chi IS NOT NULL
GROUP BY ia_chi
ORDER BY avg_price DESC;

-- PhÃ¢n tÃ­ch theo loáº¡i báº¥t Ä‘á»™ng sáº£n
SELECT 
    property_type,
    COUNT(*) as count,
    AVG(muc_gia::float) as avg_price,
    AVG(dien_tich::float) as avg_area
FROM real_estate_properties
WHERE property_type IS NOT NULL
GROUP BY property_type
ORDER BY count DESC;
```

### Python Analytics vá»›i PostgreSQL

Sá»­ dá»¥ng SQLAlchemy hoáº·c pandas Ä‘á»ƒ káº¿t ná»‘i vÃ  phÃ¢n tÃ­ch:

```python
import pandas as pd
import sqlalchemy as sa
import matplotlib.pyplot as plt
import seaborn as sns

# Káº¿t ná»‘i PostgreSQL
engine = sa.create_engine('postgresql://user:password@host:port/database')

# Query dá»¯ liá»‡u
query = """
SELECT 
    muc_gia::float as price,
    dien_tich::float as area,
    ia_chi as location,
    latitude,
    longitude
FROM real_estate_properties
WHERE muc_gia IS NOT NULL 
  AND dien_tich IS NOT NULL 
  AND latitude IS NOT NULL
"""

df = pd.read_sql(query, engine)

# Visualization
plt.figure(figsize=(12, 8))
sns.scatterplot(data=df, x='area', y='price', alpha=0.6)
plt.title('GiÃ¡ báº¥t Ä‘á»™ng sáº£n theo diá»‡n tÃ­ch')
plt.xlabel('Diá»‡n tÃ­ch (mÂ²)')
plt.ylabel('GiÃ¡ (tá»· VNÄ)')
plt.show()

# Thá»‘ng kÃª theo khu vá»±c
location_stats = df.groupby('location').agg({
    'price': ['count', 'mean', 'median'],
    'area': 'mean'
}).round(2)

print(location_stats.head(10))
```

Sau khi pipeline hoÃ n thÃ nh, sá»­ dá»¥ng script `postgres_analytics.py` Ä‘á»ƒ cháº¡y analytics queries trÃªn dá»¯ liá»‡u PostgreSQL:

```bash
cd src/pipelines/real-estate

# Cháº¡y analytics queries trÃªn dá»¯ liá»‡u PostgreSQL
python postgres_analytics.py

# Vá»›i tÃ¹y chá»n giá»›i háº¡n káº¿t quáº£
python postgres_analytics.py --limit-results 20
```


### Jupyter Notebook (TÃ¹y chá»n)

Pipeline cÅ©ng há»— trá»£ Jupyter notebook vá»›i DuckDB Ä‘á»ƒ query data tá»« Delta Lake trÃªn MinIO:

```python
import duckdb
import pandas as pd

# Cáº¥u hÃ¬nh káº¿t ná»‘i MinIO
duckdb.sql("""
INSTALL httpfs;
LOAD httpfs;
SET s3_endpoint='127.0.0.1:9000';
SET s3_access_key_id='minioadmin';
SET s3_secret_access_key='minioadmin';
""")

# Query data tá»« Delta Lake
df = duckdb.sql("SELECT * FROM read_parquet(['s3://real-estate/lake/bronze/property/*.parquet'])").df()
```

### Data Schema

Dá»¯ liá»‡u thu tháº­p bao gá»“m:
- `url`: Link bÃ i Ä‘Äƒng
- `tieu_e`: TiÃªu Ä‘á» báº¥t Ä‘á»™ng sáº£n  
- `muc_gia`: GiÃ¡ (tá»·/triá»‡u VNÄ)
- `dien_tich`: Diá»‡n tÃ­ch (mÂ²)
- `ia_chi`: Äá»‹a chá»‰ chi tiáº¿t
- `latitude/longitude`: Tá»a Ä‘á»™ GPS
- `propertydetails_propertyid`: ID unique (hash tá»« URL)
- `ngay_ang`: NgÃ y thu tháº­p dá»¯ liá»‡u

### Export tÃ­ch há»£p trong Pipeline

Export dá»¯ liá»‡u tá»« Delta Lake sang PostgreSQL Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p trá»±c tiáº¿p vÃ o pipeline Dagster. Khi cháº¡y job `scrape_realestate`, pipeline sáº½ tá»± Ä‘á»™ng:

1. âœ… **Scrape dá»¯ liá»‡u** tá»« nhadat247.com.vn
2. âœ… **LÆ°u vÃ o Delta Lake** trÃªn MinIO S3-compatible
3. âœ… **Export sang PostgreSQL** vá»›i schema auto-detection
4. âœ… **Táº¡o indexes** cho performance
5. âœ… **Verify dá»¯ liá»‡u** sau export


### Cáº¥u hÃ¬nh PostgreSQL

File `postgres_credentials.yaml` chá»©a thÃ´ng tin káº¿t ná»‘i:

```yaml
postgresql:
  host: your-postgres-host
  port: 5432
  database: your-database
  user: your-username
  password: your-password
```

## Acknowledgments

- [Dagster](https://dagster.io/) - Workflow orchestration
- [Delta Lake](https://delta.io/) - Data lakehouse
- [PostgreSQL](https://postgresql.org/) - Relational database
- [SQLAlchemy](https://sqlalchemy.org/) - Python SQL toolkit
- [MinIO](https://min.io/) - Object storage
- [nhadat247.com.vn](https://nhadat247.com.vn) - Data source

