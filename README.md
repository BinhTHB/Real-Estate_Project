# Real Estate Project

Má»™t pipeline data engineering thá»±c táº¿ Ä‘á»ƒ thu tháº­p, xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u báº¥t Ä‘á»™ng sáº£n Viá»‡t Nam tá»« nhadat247.com.vn.

## Má»¥c lá»¥c

- [Kiáº¿n trÃºc dá»± Ã¡n](#-kiáº¿n-trÃºc-dá»±-Ã¡n)
- [TÃ­nh nÄƒng chÃ­nh](#-tÃ­nh-nÄƒng-chÃ­nh)
- [CÃ´ng nghá»‡ sá»­ dá»¥ng](#ï¸-cÃ´ng-nghá»‡-sá»­-dá»¥ng)
- [CÃ i Ä‘áº·t vÃ  cháº¡y](#-cÃ i-Ä‘áº·t-vÃ -cháº¡y)
- [Sá»­ dá»¥ng pipeline](#-sá»­-dá»¥ng-pipeline)
- [Data Exploration](#-data-exploration)
- [Cáº¥u trÃºc thÆ° má»¥c](#-cáº¥u-trÃºc-thÆ°-má»¥c)

## Kiáº¿n trÃºc dá»± Ã¡n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Scraping  â”‚ -> â”‚   Data Process  â”‚ -> â”‚   Delta Lake    â”‚ -> â”‚   Data Explore  â”‚
â”‚  (Requests + BS)â”‚    â”‚   (Pandas)      â”‚    â”‚   (MinIO S3)    â”‚    â”‚   (Jupyter)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Dagster     â”‚         â”‚    Analytics    â”‚
                    â”‚ Orchestration  â”‚         â”‚   (DuckDB)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Luá»“ng xá»­ lÃ½ dá»¯ liá»‡u:
1. **Scraping Layer**: Thu tháº­p dá»¯ liá»‡u tá»« nhadat247.com.vn sá»­ dá»¥ng requests + BeautifulSoup, trÃ¡nh DNS issues
2. **Processing Layer**: Xá»­ lÃ½ dá»¯ liá»‡u vá»›i Pandas, chuáº©n hÃ³a format
3. **Storage Layer**: LÆ°u trá»¯ ACID vá»›i Delta Lake trÃªn MinIO S3-compatible
4. **Exploration Layer**: PhÃ¢n tÃ­ch dá»¯ liá»‡u vá»›i Jupyter notebooks vÃ  DuckDB

**Key Data Flow**: Search Criteria â†’ URL Generation â†’ Threaded Requests Scraping â†’ DataFrame Processing â†’ Delta Lake Merge â†’ Jupyter Exploration

## TÃ­nh nÄƒng chÃ­nh

- âœ… **Web Scraping á»•n Ä‘á»‹nh**: Sá»­ dá»¥ng requests + BeautifulSoup, trÃ¡nh DNS issues cá»§a Chrome/Selenium
- âœ… **ACID Transactions**: Delta Lake Ä‘áº£m báº£o tÃ­nh toÃ n váº¹n dá»¯ liá»‡u
- âœ… **Schema Evolution**: Tá»± Ä‘á»™ng adapt khi schema thay Ä‘á»•i
- âœ… **Cloud Storage**: MinIO S3-compatible cho storage agnostic
- âœ… **Data Exploration**: Jupyter notebooks vá»›i DuckDB analytics
- âœ… **Monitoring**: Dagster UI cho pipeline monitoring

## ğŸ› ï¸ CÃ´ng nghá»‡ sá»­ dá»¥ng

### Core Dependencies
- **Dagster 1.6.8**: Workflow orchestration vÃ  pipeline management
- **Dagster-DeltaLake-Pandas**: Delta Lake integration vá»›i Pandas
- **Delta Lake**: ACID transactions vÃ  time travel cho data lake
- **MinIO**: S3-compatible object storage
- **PyArrow**: Apache Arrow cho data processing
- **Pandas**: Data manipulation vÃ  analysis
- **DuckDB**: In-process analytical database (sá»­ dá»¥ng trong notebooks)
- **Requests**: HTTP client cho web scraping
- **BeautifulSoup4**: HTML parsing
- **Boto3**: AWS S3 API client (MinIO compatible)

### Development & Deployment
- **Dagstermill**: Jupyter notebook integration vá»›i Dagster

## CÃ i Ä‘áº·t vÃ  cháº¡y

### Prerequisites
- Python 3.8+
- Git
- Windows OS

### 1. Clone repository
```bash
git clone https://github.com/BinhTHB/Real-Estate_Project.git
cd Real-Estate_Project
```

### 2. CÃ i Ä‘áº·t dependencies
```bash
cd src/pipelines/real-estate

# KÃ­ch hoáº¡t virtual environment (náº¿u cÃ³)
# .\venv\Scripts\activate  

pip install -e ".[dev]"
```

Dependencies chÃ­nh bao gá»“m:
- Dagster ecosystem (dagster, dagstermill, dagster-aws, dagster-postgres, dagster-deltalake)
- Data processing (pandas, pyarrow, numpy, scipy, scikit-learn)
- Web scraping (requests, beautifulsoup4)
- Cloud storage (boto3)
- Analytics (duckdb, seaborn, matplotlib, folium)
- Development (pytest, notebook)

### 3. Khá»Ÿi Ä‘á»™ng MinIO storage
```bash
minio server /tmp/minio/
```

MinIO sáº½ cháº¡y táº¡i:
- **API Endpoint**: `http://127.0.0.1:9000`
- **Username**: `minioadmin`
- **Password**: `minioadmin`

### 4. Startup dagster
```bash
dagster dev
```

## Sá»­ dá»¥ng pipeline

### Cháº¡y pipeline scraping

1. Má»Ÿ Dagster UI táº¡i http://127.0.0.1:3000
2. Chá»n job `scrape_realestate`
3. Launch vá»›i configuration máº·c Ä‘á»‹nh hoáº·c tÃ¹y chá»‰nh:

```yaml
# scrape_realestate.yaml
solids:
  collect_search_criterias:
    inputs:
      search_criterias:
        - city: "hanoi"
          propertyType: "can-ho-chung-cu"
          rentOrBuy: "buy"
          radius: 0
```

### Monitoring pipeline

Dagster UI cung cáº¥p:
- âœ… **Pipeline runs**: Lá»‹ch sá»­ executions
- âœ… **Logs**: Chi tiáº¿t tá»«ng step
- âœ… **Data lineage**: Flow cá»§a data
- âœ… **Asset catalog**: Datasets Ä‘Æ°á»£c táº¡o

## ğŸ” Data Exploration

### Jupyter Notebook

Pipeline tá»± Ä‘á»™ng cháº¡y notebook `main_notebook.ipynb` sau khi scrape data. Notebook sá»­ dá»¥ng DuckDB Ä‘á»ƒ query data tá»« Delta Lake trÃªn MinIO:

```python
# Trong notebook cÃ³ thá»ƒ:
import duckdb
import pandas as pd

# Cáº¥u hÃ¬nh káº¿t ná»‘i MinIO
duckdb.sql("""
INSTALL httpfs;
LOAD httpfs;
SET s3_endpoint='127.0.0.1:9000';
SET s3_access_key_id='minioadmin';
SET s3_secret_access_key='minioadmin';
""")

# Query data tá»« Delta Lake
df = duckdb.sql("SELECT * FROM read_parquet(['s3://real-estate/lake/bronze/property/*.parquet'])").df()

# Analytics vá»›i DuckDB
result = duckdb.sql("""
    SELECT
        "Má»©c giÃ¡",
        "Diá»‡n tÃ­ch", 
        latitude,
        longitude,
        COUNT(*) as count
    FROM df
    GROUP BY "Má»©c giÃ¡", "Diá»‡n tÃ­ch", latitude, longitude
""").df()
```

### Data Schema

Dá»¯ liá»‡u thu tháº­p bao gá»“m:
- `url`: Link bÃ i Ä‘Äƒng
- `TiÃªu Ä‘á»`: TiÃªu Ä‘á» báº¥t Ä‘á»™ng sáº£n  
- `Má»©c giÃ¡`: GiÃ¡ (tá»·/triá»‡u VNÄ)
- `Diá»‡n tÃ­ch`: Diá»‡n tÃ­ch (mÂ²)
- `Äá»‹a chá»‰`: Äá»‹a chá»‰ chi tiáº¿t
- `latitude/longitude`: Tá»a Ä‘á»™ GPS
- `propertyDetails_propertyId`: ID unique (hash tá»« URL)
- `NgÃ y Ä‘Äƒng`: NgÃ y thu tháº­p dá»¯ liá»‡u

## Cáº¥u trÃºc thÆ° má»¥c

```
Real-Estate_Project/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ pipelines/
â”‚       â””â”€â”€ real-estate/
â”‚           â”œâ”€â”€ realestate/           # Core pipeline code
â”‚           â”‚   â”œâ”€â”€ pipelines.py      # Main job definitions vÃ  orchestration
â”‚           â”‚   â”œâ”€â”€ resources.py      # Dagster resources (database/S3 configs)
â”‚           â”‚   â”œâ”€â”€ common/           # Shared utilities
â”‚           â”‚   â”‚   â”œâ”€â”€ requests_scraping.py    # Web scraping logic (requests + BS4)
â”‚           â”‚   â”‚   â”œâ”€â”€ solids_spark_delta.py   # Delta Lake operations (merge/upsert)
â”‚           â”‚   â”‚   â”œâ”€â”€ types_realestate.py     # Custom data types
â”‚           â”‚   â”‚   â”œâ”€â”€ helper_functions.py     # Utility functions
â”‚           â”‚   â”‚   â”œâ”€â”€ solids_jupyter.py       # Notebook integration
â”‚           â”‚   â”‚   â””â”€â”€ resources.py            # Resource definitions (boto3, etc.)
â”‚           â”‚   â”œâ”€â”€ config_environments/        # Environment configs (local/prod)
â”‚           â”‚   â”œâ”€â”€ config_pipelines/          # Pipeline execution parameters
â”‚           â”‚   â””â”€â”€ notebooks/                 # Data exploration notebooks
â”‚           â”œâ”€â”€ setup.py                       # Package setup vá»›i dependencies
â”‚           â”œâ”€â”€ pyproject.toml                 # Project metadata
â”‚           â”œâ”€â”€ dev-requirements.txt           # Development dependencies
â”‚           â””â”€â”€ tox.ini                        # Testing configuration
â”œâ”€â”€ lake/bronze/                  # Delta Lake storage (runtime)
â”œâ”€â”€ PRODUCTION_FEATURES_GUIDE.md   # Production deployment guide
â”œâ”€â”€ .github/copilot-instructions.md # AI assistant instructions
â””â”€â”€ README.md                      # This file
```

## Acknowledgments

- [Dagster](https://dagster.io/) - Workflow orchestration
- [Delta Lake](https://delta.io/) - Data lakehouse
- [MinIO](https://min.io/) - Object storage
- [nhadat247.com.vn](https://nhadat247.com.vn) - Data source

